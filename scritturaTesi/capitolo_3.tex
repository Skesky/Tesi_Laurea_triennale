La realizzazione di questo simulatore per la distribuzione quantistica di chiavi con modulazione gaussiana si prefigge lo scopo di realizzare una chiave crittografica sicura condivisa tra due parti, la quale successivamente potr\`a essere utilizzate per la codifica e decodifica di un messaggio trasmesso su un canale pubblico classico. 

Per lo sviluppo del simularore \`e stato utilizzato il linguaggio di programmazione C++. I motivi principali di questa scelta sono tre: la velocit\`a del linguaggio di programmazione, la disponibilit\`a di librerie che implementano le distribuzioni di probabilit\`a necessarie alla simulazione e la presenza di librerie esterne che implementano due algoritmi indispensabili per la correzione degli errori.

Anche se il progetto \`e stato realizzato utilizzando C++ \`e stato deciso di illustrare quanto \`e stato fatto attraverso dello psdeudo-codice in modo tale da non legare la simulazione ad una specifico linguaggio di programmazione ed agevolarne la re-implementazione in qualunque linguaggio di programmazione si voglia utilizzare.

Prima di addentranci nella descrizione delle fasi della simulazione, \`e bene andare a definire delle costanti necessarie per il corretto funzionamente del simulatore. Le costanti in questione sono il rumore e la trasmittanza del canale, rispettivamente $\xi = 0.005$ e $T=0.1$, la varianza $V_{mod}=5.226$ della modulazione ed il code-rate $R = 0.3$. I valori per queste costanti sono stati scelti in base ai risultati ottenuti negli articoli~\cite{https://doi.org/10.1002/qute.201800011} e \cite{e24101463}.

\section{Preparazione, trasmissione e misura}

\subsection{Preparazione dello stato coerente}\label{subse:prep-stato}
Per la realizzazione degli stati coerenti da trasmettere sul canale vengono scelti due valori che rappresentano i valori medi delle due gaussiane con varianza unitaria che caratterizzano lo stato. I valori vengono estratti a loro volta da una distribuzione di probabilit\`a normale centratata in zero e con varianza $V_{mod}$. Queste informazioni sono salvate in una struttura dati che, oltre a contenere tutte le informazioni necessarie per caratterizzare lo stato coerente, presenta dei tag che verranno utilizzati nella sottosezione~\ref{subse:sifting} per distinguere le componenti di quadratura $p$ e $q$.

\subsection{Trasmissione su canale rumoroso}
Per ogni stato coerente prodotto si simula la trasmissione in un canale rumoroso. Le operazioni che vengono effettuate in pratica sono: il prodotto dei valori medi della gaussiane per la radice quadrata della trasmittanza e la somma di $\xi$ alla varianza. Quindi le le componenti di quadratura saranno descritte come nell'espressione~\ref{eq:stato-bob}.

\subsection{Misura omodina del segnale}
Per la misurazione del segnale verr\`a effettuata una misura omodina che consiste in due fasi. Per prima cosa si decide quale delle componenti di quadratura misurare: la decisione viene presa attraverso un distribuzione di probabilit\`a uniforme. Questo significa che le componenti $q$ e $p$ hanno la stessa probabilit\`a di essere misurate.

Successivamente avviene l'effetiva misura che consiste nell'estrarre un valore da una delle due distribuzione normali:
\begin{equation}\label{eq:normal_dist_bob}
\begin{split}
Q_B \sim \mathcal N(\sqrt{T} q_B, 1 + \xi) \\
P_B \sim \mathcal N(\sqrt{T} p_B, 1 + \xi)
\end{split}
\end{equation}

\section{Sifting}\label{se:sifting}
Prima di procedere con l'effettiva stima dei parametri \`e necessario effettuare il sifting (vaglio delle informazioni). A questo punto della simulazione si hanno gli stati coerenti inviati e l'insieme delle misure delle componenti. Dal momento che viene effettuata la misura di una sola componente per ogni round di trasmissione, i dati trasmessi sono il doppio di quelli misurati. L'operazione che viene effettuata \`e molto semplice: per ogni misura effettuata viene determinata quale componente \`e stata misurata, questo grazie al tag di cui abbiamo parlato nella sottosezione~\ref{subse:prep-stato}; per il round di trasmissione corrispondente vengono mantenute solamente le informazioni di valore medio e tag relative alla componente misurata scartando il resto.

Questa operazione viene effettata per ogni coppia di dati trasmessi e misurati.

\section{Stima dei parametri}
La stima dei parametri \`e una fase indispensabile del protocollo perch\'e permette di determinare se la trasmissione \`e stata sicura oppure \`e avvenuta l'intromissione di una spia. Per la stima dei parametri Alice e Bob dovrebbero scambiarsi un subset random dei dati trasmessi ma per semplicit\`a nella simulazione utilizziamo i primi $n$ dati trasmessi. In un'applicazione reale del protocollo questa \`e una pessima scelta, perch\'e se Eve venisse in possesso di questa informazione potrebbe non intercettare i primi $n$ segnali andando a misurare solo la restante parte. Cos\`i facendo Eve non verrebbe rilevata pur avendo intercettato la parte pi\'u importante della comunicazione, cio\`e i dati che verranno utilizzati per distillare la chiave.

Chiamiamo i subset di dati dopo il sifting di Alice e Bob utilizzati per la stima dei parametri $Q_A$ e $Q_B$ per la componente di quadrature $q$ e $P_A$ e $P_B$ per la componente di quadratura $p$.

Svolte tutte le operazioni illustrate dall'algoritmo~\ref{al:stima-param} per ottenere la stima dell'informazione mutua tra Alice e Bob $I_{AB}$ e di quella tra Eve e Bob $\chi_{EB}$ le andiamo a confrontare. Nel caso in cui $I_{AB}$ risulti minore di $\chi_{EB}$ la simulazione si interrompe e deve ricominciare da capo.

\begin{algorithm}[H]
\caption{: Stima dei parametri}\label{al:stima-param}
\begin{algorithmic}[1]
\State \textbf{Step 1:} Stima dei parametri a, b e c \newline
	$a \leftarrow V_{mod} + 1$ \newline
	$b \leftarrow \frac{\langle Q_B^2 \rangle + \langle P_B^2\rangle}{2} $ \newline
	$c \leftarrow \sqrt{\frac{V_{mod} + 2}{V_{mod}}} \cdot \frac{\langle Q_BQ_A \rangle + \langle P_BP_A\rangle}{2}$ 
\State \textbf{Step 2:} Stima del rumore e della trasmittanza del canale \newline
	$T \leftarrow \frac{c^2}{V_{mod}^2 + 2 V_{mod}}$ \newline
	$\xi \leftarrow b - TV_{mod} -1 $ 
\State \textbf{Step 3:} Calcolo dei $\nu$ \newline
	$\textbf{$\nu$} \leftarrow nuCalc()$  		 \Comment vengono utilizzare le equazioni \ref{eq:nuCalc}
\State \textbf{Step 4:} Calcolo $I_{AB}$ \newline
	$SNR \leftarrow signalNoiseRatio()$	\Comment viene utilizzata l'equazione \ref{eq:snr}	
	$I_{AB} \leftarrow mutualInfoAliceBob(SNR)$	\Comment viene utilizzata l'equazione \ref{eq:AB-info}
\State \textbf{Step 5:} Calcolo $\chi_{EB}$ \newline
	$\chi_{EB} \leftarrow g(\nu_1) + g(\nu_2) - g(\nu_3)$	\Comment la funzione $g(\nu)$ \ref{eq:g}						
\State \textbf{Step 6:} Confronto tra $I_{AB}$ e $\chi_{EB}$  \newline
	$\beta \leftarrow \frac{R}{I_{AB}}$	\Comment R rappresenta in code-rate
	\If {$\beta I_{AB} < \chi_{EB}$}
		\State	$abort()$		\Comment la simulazione si interrompe
	\EndIf
\end{algorithmic}
\end{algorithm}


\section{Riconciliazione}
A questo punto della simulazione si \`e in possesso del subset di dati non utilizzati per la stima dei parametri che andiamo a chiamare $\textbf{X}_0$ e $\textbf{Y}_0$; prima di effettuare la reconciliazione vengono prodotte, a partire da questi dati, altre due sequenze di dati correlati che chiameremo $\textbf{X}$ e $\textbf{Y}$ come illustrato nell'equazione~\ref{eq:normalizzazione}. 

Poi viene prodotta la stringa $\textbf{s}$ la quale viene codificata attraverso l'algoritmo PEG (Progressive Edge Growth) per ottente la stringa $\textbf{c}$. Utilizziamo la stringa $\textbf{c}$ per modulare il segno della sequenza di dati $\textbf{Y}$ di Bob per produrre il messaggio  $\textbf{m}$ che verr\`a inviato ad Alice. Da messaggio  $\textbf{m}$ Alice estrarr\`a un messaggio fittizio $\textbf{r}$ con $r_i = \frac{m_i}{X_i}$ che corrisponde alla trasmisione su un canale Gaussiano con rumore di varianza $V_i = \frac{V_z}{|X_i|}$.

Per tutti gli elementi del messaggio \textbf{r} vengono calcolati i valori di varianza che a loro volta vengono utilizzati per calcolare le LLRs (log-likelihood ratios) che sono definite come~\cite{gumucs2021novel}:
\begin{equation}
l_i = \log \frac{P(R_i = r_i| C_i = 0)}{P(R_i = r_i| C_i = 1)} = \frac{2r_i}{V_i}
\end{equation}

Le LLRs sono il logaritmo del rapporto tra la probabilit\`a condizionata che il messaggio $r_i$ provenisse effettivamente da un bit $0$ e la probabilit\'a che il messaggio $r_i$ provenisse da un bit $1$. I valori di LLRs permettono ad Alice, grazie all'utilizzo di un algoritmo LDPC di decodifica~\ref{al:sum-prod}, di ottenere una stima $\textbf{c'}$ della stringa $\textbf c$ prodotta da Bob.


%che le permettar\`a, attraverso l'utilizzo dell'algoritmo $\textit{sum-product}$~\ref{al:sum-prod}, di ottenere una stima della stringa di bit $\textbf{c}$ prodotta originariamente da Bob.

Tutte queste operazioni vengono illustrate nell'algoritmo~\ref{al:recon} facendo riferimento alla sottosezione~\ref{subse:riconciliazione}.

\begin{algorithm}[t]
\caption{: Riconciliazione}\label{al:recon}
\begin{algorithmic}[1]
\State \textbf{Step 1:} Genera string di bit random
	\State $\textbf{s} \leftarrow generaStringaBit()$	\Comment $\textbf{s} \in \{0,1\}^k$
\State \textbf{Step 2:} Crea la matrice $\textbf{H}$ e la matrice $\textbf{G}$
	\State $\textbf{H} \leftarrow peg(M,N, \lambda )$	\Comment {l'algoritmo PEG prendo come parametri il grado dei } 
	\State {}							\Comment { nodi variabile, il numero di righe e di colonne}
	\State $ \textbf{G} \leftarrow generaG(\textbf{H})$
\State \textbf{Step 3:} Genera la code-word
	\State $\textbf{c} \leftarrow \textbf{s} \times \textbf{G}$
\State \textbf{Step 4:} Viene modulato il segno dei dati di Bob
	\State $\textbf{m} \leftarrow modulazione(\textbf{Y})$
\State \textbf{Step 5:} Estrazione del messaggi fittizio da parte di Alice e calcolo LLR
	\State $\textbf{r} \leftarrow messaggioFittizio(\textbf{m})$
	\State $\textbf{LLR} \leftarrow calcoloLLR(\textbf{r}, \textbf{X})$
\State \textbf{Step 6:} Stima della code-word
	\State $\textbf{c'} \leftarrow sumProd(LLR, H)$
\end{algorithmic}
\end{algorithm}

%Per tutti gli elementi del messaggio $\underline{r}$ vengono calcolati i valori di varianza che a loro volta vengono utilizzati per calcolare la log likelihood ratios (LLRs) che sono definite come~\cite{gumucs2021novel}:
%\begin{equation}
%l_i = \log \frac{P(R_i = r_i| C_i = 0)}{P(R_i = r_i| C_i = 1)} = \frac{2r_i}{V_i}
%\end{equation}



\subsection{Algoritmi Sum-Product e classic PEG}\label{subse:algorithms}
L'algoritmo LDPC utilizzato per la decodifica nella simulazione prende in nome di \textit{sum-product}~\ref{al:sum-prod}. Questo algoritmo utilizza la tecnica di \textit{belief propagation} creando per i nodi check e i nodi variabile dei messaggi. Questi messaggi vengono aggiornati ad ogni iterazione dell'algoritmo e permettono, a loro volta, di aggiornaee i valori delle LLRs.

Per quanto riguarda la codifica abbiamo utilizzato l'algoritmo \textit{classic-peg}, il quale realizza la matrice di parit\`a rappresentata come un grafo partendo dalla dimensione della matrice che si vuole ottenere e da quantit\`a $\Lambda$ che rappresentano le frazioni dei nodi variabile che avranno un certo grado. \`E possibile calcolare le componenti del vettore $\Lambda$ in questo modo:
\begin{equation}
\Lambda_i = \frac{r_i}{\sum_i r_i}
\end{equation}
dove $r_i$ vengono calcolati come segue:
\begin{equation}
r_i = \frac{\lambda_i}{i}
\end{equation}
a partire da delle quantit\`a $\lambda_i$ che prendono il nome di node degree distribution e rappresentano la frazione di archi collegati ad un nodo variabile di grado $i$.

Tutti i valori del vettore $\lambda$, i gradi dei nodi da utilizzare e l'espressione per il calcolo del vettore $\Lambda$ fanno riferimento ai risultati ottenuti nell'articolo \cite{e24101463} in merito al code-rate ed al valore di SNR da noi scelto.

Come abbiamo detto l'algoritmo \textit{classic-peg} prende input la dimensione della matrice di parit\`a e quindi il numero di nodi check e nodi variabile del grafo oltre che la frazione di nodi di un certo grado.

L'algoritmo \textit{classic-peg} genera il grafo, partendo dai parametri in input, iterando su tutti i nodi variabile ed aggiungendo archi che collegano il nodo variabile ai nodi check. Si passa al nodo variabile successivo solamente quando tutti gli archi richiesti per quel nodo sono stati creati. Per la creazione di un nuovo arco ci sono due scelte possibili:
\begin{itemize}
\item il nodo variabile corrente non presenta ancora nessun arco, in questo caso viene creato un arco che lo collega al nodo check con minor numero di archi tra tutti i nodi check disponibili;
\item il nodo variabile corrente presenta gi\`a altri archi, in questo caso si hanno due scenari:
\begin{itemize}
\item ci sono dei nodi che non appartengono al sottografo del nodo variabile corrente. Viene creato un arco tra il nodo variabile corrente ed il nodo check con meno archi che non appartiene al sottografo;
\item il sottografo del nodo corrente copre tutti i nodi del grafo. In questo caso si sceglie il nodo check pi\`u lontano dall'attuale nodo variabile.
\end{itemize}
\end{itemize}

L'algoritmo è così strutturato per ridurre il numero di sotto-cicli nel grafo finale, che andrebbe a rendere la correzione di errori meno efficiente.

\begin{algorithm} 
\caption{: Sum-product decoding algorithm}\label{al:sum-prod}
\begin{algorithmic}
\State \textbf{Step 1: }Inizializzazione dei messaggi dei nodi variabile $L(q_{i,j})^{\langle 0 \rangle}$
\For {$i \leftarrow 0; M$}
	\For {$j \leftarrow 0; N$} 
		\State $L(q_{i,j})^{\langle 0 \rangle} \leftarrow LLRs_i$
	\EndFor
\EndFor
\For {$k \leftarrow 1; maxRound $}
	\State \textbf{Step 2: } Calcola messaggi di check
	\For {$i \leftarrow 0; N$}
		\State $tmp \leftarrow 1$
		\For {$j \leftarrow 0; M$}
			\ForEach {$w \in  C_i $}
				\If {$w \neq i$}
					\State $tmp \leftarrow tmp * \tanh \Bigl ( \frac{1}{2}L(q_{w,j})^{\langle k-1 \rangle} \Bigr ) $
				\EndIf
			\EndFor
		\State $L(r_{j,i})^{\langle k \rangle} \leftarrow 2 \tanh^{-1} (tmp)$
		\EndFor
	\EndFor
	
	\State \textbf{Step 3: }Aggiorna i messaggi dei nodi variabile 
	\For {$i \leftarrow 0; N$}
		\For {$j \leftarrow 0; M$}
		\State $tmp \leftarrow 0$
			\ForEach {$w \in  V_i $}
				\If {$w \neq i$}
					\State $tmp \leftarrow tmp + L(r_{w,i})^{\langle k \rangle} $
				\EndIf
			\EndFor
		\State $L(q_{i,j})^{\langle k \rangle} \leftarrow LLRs_i + tmp$
		\EndFor
	\EndFor
\State  \textbf{Step 4: }Aggiorna \textbf{LLRs} aggiornate
\For {$i \leftarrow 0; \textbf{LLRs}.size()$}
	\State $tmp \leftarrow 0$
	\ForEach{$ j \in V_i $}
		\State $tmp \leftarrow tmp + L(r_{i,j})^{\langle k \rangle}$
	\EndFor
	\State {$ L(Q_i) \leftarrow LLRs_i + tmp$}
\EndFor
\EndFor
\State \textbf{Step 5: }Stima \textbf{C}
\For {$i \leftarrow 1; \textbf{LLRs}.size()$}
	\If {$LLRs_i \geq 0$}
		\State$C_i \leftarrow 0$
	\Else
		\State$C_i \leftarrow 1$
	\EndIf
\EndFor

\end{algorithmic}
\end{algorithm}


%\begin{algorithm}
%\caption{: Classic PEG algorithm}
%\begin{algorithmic}
%\STATE Input:  \STATE output
%\end{algorithmic}
%\end{algorithm}





